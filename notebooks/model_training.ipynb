{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\LENOVO\\\\Animal_Classifier\\\\notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\LENOVO\\\\Animal_Classifier'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Setup\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📂 Load and Preprocess Dataset\n",
    "We load the images from the `dataset/` folder using TensorFlow's `image_dataset_from_directory`.\n",
    "We then normalize the pixel values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1944 files belonging to 15 classes.\n",
      "Using 1556 files for training.\n",
      "Found 1944 files belonging to 15 classes.\n",
      "Using 388 files for validation.\n"
     ]
    }
   ],
   "source": [
    "#  Load Dataset\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "DATASET_PATH = \"dataset/\"\n",
    "\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    DATASET_PATH, validation_split=0.2, subset=\"training\", seed=123,\n",
    "    image_size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    DATASET_PATH, validation_split=0.2, subset=\"validation\", seed=123,\n",
    "    image_size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Normalize the images\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_dataset = val_dataset.map(lambda x, y: (normalization_layer(x), y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🧠 Define the Model (Transfer Learning)\n",
    "We use MobileNetV2 as a base model and build a classifier on top of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(15, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🏋️‍♂️ Train the Model in Two Phases\n",
    "- Phase 1: Train only the top layers.\n",
    "- Phase 2: Unfreeze and fine-tune the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.9466 - loss: 0.1665 - val_accuracy: 0.8943 - val_loss: 0.3185\n",
      "Epoch 2/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - accuracy: 0.9663 - loss: 0.1035 - val_accuracy: 0.8995 - val_loss: 0.3015\n",
      "Epoch 3/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.9781 - loss: 0.0799 - val_accuracy: 0.9149 - val_loss: 0.2777\n",
      "Epoch 4/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - accuracy: 0.9826 - loss: 0.0587 - val_accuracy: 0.8969 - val_loss: 0.3256\n",
      "Epoch 5/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.9871 - loss: 0.0491 - val_accuracy: 0.8969 - val_loss: 0.3163\n"
     ]
    }
   ],
   "source": [
    "#' Phase 1 Training (frozen base model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history_1 = model.fit(train_dataset, validation_data=val_dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 7s/step - accuracy: 0.8327 - loss: 0.5825 - val_accuracy: 0.9046 - val_loss: 0.2834\n",
      "Epoch 2/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 7s/step - accuracy: 0.9107 - loss: 0.2604 - val_accuracy: 0.9175 - val_loss: 0.2484\n",
      "Epoch 3/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 6s/step - accuracy: 0.9351 - loss: 0.2165 - val_accuracy: 0.9227 - val_loss: 0.2236\n",
      "Epoch 4/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 6s/step - accuracy: 0.9595 - loss: 0.1347 - val_accuracy: 0.9253 - val_loss: 0.2072\n",
      "Epoch 5/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 6s/step - accuracy: 0.9549 - loss: 0.1391 - val_accuracy: 0.9330 - val_loss: 0.1943\n"
     ]
    }
   ],
   "source": [
    "# Phase 2 Training (fine-tune base model)\n",
    "base_model.trainable = True\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history_2 = model.fit(train_dataset, validation_data=val_dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 💾 Save the Trained Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "model.save(\"models/cnn_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📊 Plot Accuracy\n",
    "Visualize how the model's accuracy evolved over the training epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Accuracy\n",
    "train_acc = history_1.history['accuracy'] + history_2.history['accuracy']\n",
    "val_acc = history_1.history['val_accuracy'] + history_2.history['val_accuracy']\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_acc, label=\"Train Accuracy\")\n",
    "plt.plot(val_acc, label=\"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Model Accuracy Over Epochs\")\n",
    "plt.savefig(\"training_accuracy_plot.png\", dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
